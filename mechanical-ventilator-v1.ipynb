{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-24T16:37:31.319239Z","iopub.execute_input":"2022-08-24T16:37:31.319957Z","iopub.status.idle":"2022-08-24T16:37:31.353414Z","shell.execute_reply.started":"2022-08-24T16:37:31.319855Z","shell.execute_reply":"2022-08-24T16:37:31.352280Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"print(\"Started\")\nimport numpy as np, pandas as pd\nprint(\"Pandas version - \", pd.__version__)\nfrom pandas import MultiIndex, Int16Dtype\n\ntry:\n    import seaborn as sns\nexcept:\n    !pip install seaborn\n    import seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\n#import cupy, cudf\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\n\n# Importing RFE and LinearRegression\ntry:\n    import statsmodels.api as sm\nexcept:\n    !python -m pip install statsmodels\n    import statsmodels.api as sm\n\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model,tree,svm\n\ntry:\n    import pickle\nexcept:\n    !pip install pickle5\n    import pickle\n\nfrom sklearn.metrics import mean_absolute_error\nprint(\"All necessary libraries imported\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:37:31.355557Z","iopub.execute_input":"2022-08-24T16:37:31.356222Z","iopub.status.idle":"2022-08-24T16:37:33.932294Z","shell.execute_reply.started":"2022-08-24T16:37:31.356142Z","shell.execute_reply":"2022-08-24T16:37:33.930822Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\ntraindf = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntestdf = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsample_sub = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n\nprint(traindf.shape, \" - Training dataset shape\")\nprint(testdf.shape, \" - Testing dataset shape\")\nprint(sample_sub.shape, \" - Sample Submission dataset shape\")","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:37:33.935104Z","iopub.execute_input":"2022-08-24T16:37:33.937810Z","iopub.status.idle":"2022-08-24T16:37:48.811737Z","shell.execute_reply.started":"2022-08-24T16:37:33.937754Z","shell.execute_reply":"2022-08-24T16:37:48.809903Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"traindf.columns\n\n# Adding feature\n\ntraindf['time_delta'] = traindf.groupby('breath_id')['time_step'].diff()\n#testdf['time_delta'] = testdf.groupby('breath_id')['time_step'].diff()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:37:48.813728Z","iopub.execute_input":"2022-08-24T16:37:48.814517Z","iopub.status.idle":"2022-08-24T16:38:06.778911Z","shell.execute_reply.started":"2022-08-24T16:37:48.814461Z","shell.execute_reply":"2022-08-24T16:38:06.777390Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Adding features in the dataframe\n\ndef add_features(df):\n    #https://www.kaggle.com/code/papernist/google-brain\n    df = df.copy()\n    \n    df_group = df.groupby(['breath_id'])\n    \n    \n    feature_list = ['u_in', 'time_step', 'cross']\n    \n    df['cross']= df['u_in'] * df['u_out']\n    df['area_out']= df['time_step'] * df['u_out']\n    df['area'] = df['time_step'] * df['u_in']\n    \n    # add\n    df['air_flow_rate'] = df['u_out'] - (df['u_in']/100.0)\n    df['air_flow_area'] = df['air_flow_rate'] * df['time_step']\n    print(\"Step-1...Completed\")\n    \n    # cumsum cummean\n    df['one'] = 1\n    df['count'] = df_group['one'].cumsum()\n    for feature in feature_list:\n        df[f'{feature}_cumsum'] = df_group[feature].cumsum()\n        df[f'{feature}_cummean'] = df[f'{feature}_cumsum'] / df['count']\n        \n    print(\"Step-2 cumsum cummean ...Completed\")\n    # lagging\n    use_lags = 4\n    for lag in range(1, use_lags+1):\n        for feature in feature_list:\n            # lag \n            df[f'{feature}_lag_{lag}'] = df_group[feature].shift(lag)\n            # inverse lag\n            df[f'{feature}_lag_inverse_{lag}'] = df_group[feature].shift(-lag)\n\n            # dif lag\n            df[f'{feature}_lag_diff_{lag}'] = df[feature] - df[f'{feature}_lag_{lag}']\n\n            # dif inverse lag\n            df[f'{feature}_lag_inverse_diff_{lag}'] = df[feature] - df[f'{feature}_lag_inverse_{lag}']\n\n            df = df.drop(columns=[f'{feature}_lag_{lag}', f'{feature}_lag_inverse_{lag}'])\n        \n    df = df.fillna(0)\n    print(\"Step-3 lagging ...Completed\")\n    \n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    df = df.fillna(0)\n    print(\"Step-4 categorical ...Completed\")\n    \n    rolling_list = [15]\n    for roll in rolling_list:\n        for feature in feature_list:\n            df[[f'{roll}_{feature}_sum',f'{roll}_{feature}_min',\n                f'{roll}_{feature}_max',f'{roll}_{feature}_mean']] = (df_group[feature]\\\n                                                                  .rolling(window=roll,min_periods=1)\\\n                                                                  .agg({f'{roll}_{feature}_sum':'sum',\n                                                                        f'{roll}_{feature}_min':'min',\n                                                                        f'{roll}_{feature}_max':'max',\n                                                                        f'{roll}_{feature}_mean':'mean'})\\\n                                                                   .reset_index(level=0,drop=True))\n    \n    print(\"Step-5 Sliding window...Completed\")\n    print()\n    \n    df = df.fillna(0)\n    df = df.drop(['id', 'breath_id','one','count'], axis=1)\n    \n    return df.astype(np.float16)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:38:06.782293Z","iopub.execute_input":"2022-08-24T16:38:06.782737Z","iopub.status.idle":"2022-08-24T16:38:06.805157Z","shell.execute_reply.started":"2022-08-24T16:38:06.782697Z","shell.execute_reply":"2022-08-24T16:38:06.803826Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = add_features(traindf)\n#test = add_features(testdf)\n\nprint(\"*\"*70)\nprint(train.shape, \" - Feature added training dataset shape\")\n#print(test.shape, \" - Features added testing dataset shape\")","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:38:06.808096Z","iopub.execute_input":"2022-08-24T16:38:06.808910Z","iopub.status.idle":"2022-08-24T16:40:25.231279Z","shell.execute_reply.started":"2022-08-24T16:38:06.808840Z","shell.execute_reply":"2022-08-24T16:40:25.229636Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"binary_col = []\nnum_col = []\n\nfor columnname in train.columns:\n  if len(set(train[columnname])) != 2:\n    num_col.append(columnname)\n  else:\n    binary_col.append(columnname)\n\ntrain_numcol = num_col.copy()\ntrain_numcol.remove('pressure')\n\nprint(len(binary_col), \"Number of Binary Categorical Columns\")\nprint(len(num_col),\"Number of Numerical Columns\")\nprint(len(binary_col)+len(num_col), \"Sum of Binary & Numerical Columns\")","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:40:25.233831Z","iopub.execute_input":"2022-08-24T16:40:25.234464Z","iopub.status.idle":"2022-08-24T16:41:47.233696Z","shell.execute_reply.started":"2022-08-24T16:40:25.234416Z","shell.execute_reply":"2022-08-24T16:41:47.232135Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = train_test_split(train, train_size = 0.7, test_size = 0.3, random_state = 100)\nprint(\"Split Done\")\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, train_test_split\n\ntrainsplitcopy = df_train.copy()\ntestsplitcopy = df_test.copy()\ntraincopy = train.copy()\n\ny_train = trainsplitcopy.pop('pressure')\nX_train = trainsplitcopy\n\ny_test = testsplitcopy.pop('pressure')\nX_test = testsplitcopy\n\ny_train_nosplit = traincopy.pop('pressure')\nX_train_nosplit = traincopy\n\n\n\nprint(\"*\"*70)\nprint(\"Splitting the data into X train & Y train\")\nprint(X_train.shape, \"X train shape\")\nprint(y_train.shape, \"Y train shape\")\n\nprint(\"*\"*70)\nprint(\"Splitting the data into X test & Y test\")\nprint(X_test.shape, \"X test shape\")\nprint(y_test.shape, \"Y test shape\")\n\nprint(\"*\"*70)\nprint(\"No Split Data\")\nprint(X_train_nosplit.shape, \"X train shape\")\nprint(y_train_nosplit.shape, \"Y train shape\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:41:47.235525Z","iopub.execute_input":"2022-08-24T16:41:47.235962Z","iopub.status.idle":"2022-08-24T16:42:01.209439Z","shell.execute_reply.started":"2022-08-24T16:41:47.235923Z","shell.execute_reply":"2022-08-24T16:42:01.208095Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#train2 = train.copy()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:42:01.212067Z","iopub.execute_input":"2022-08-24T16:42:01.212912Z","iopub.status.idle":"2022-08-24T16:42:01.218507Z","shell.execute_reply.started":"2022-08-24T16:42:01.212858Z","shell.execute_reply":"2022-08-24T16:42:01.217251Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Scaling the features\n\nscaler = MinMaxScaler().fit(X_train_nosplit[train_numcol])\ntrain_scaled_nosplit = pd.DataFrame(scaler.transform(X_train_nosplit[train_numcol]),\n                              columns = X_train_nosplit[train_numcol].columns)\ntrain_scaled_nosplit.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:42:01.220046Z","iopub.execute_input":"2022-08-24T16:42:01.220453Z","iopub.status.idle":"2022-08-24T16:42:25.189663Z","shell.execute_reply.started":"2022-08-24T16:42:01.220415Z","shell.execute_reply":"2022-08-24T16:42:25.188199Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#We will save the model performance metrics in a DataFrame\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import KFold, cross_val_score\nimport pickle\nimport numpy as np\nModel = []\nRMSE = []\nR_sq = []\ncv = KFold(5, random_state = 1,shuffle=True)\n\n#Creating a Function to append the cross validation scores of the algorithms\ndef input_scores(name, model, x, y):\n    Model.append(name)\n    ts1 = time.time()\n    print(name,\" - Started\")\n    rmse_tmp = np.sqrt((-1) * cross_val_score(model, x, y, cv=cv, scoring='neg_mean_squared_error').mean())\n    RMSE.append(rmse_tmp)\n    print(name, \" - RSME - \", rmse_tmp)\n    #Pickle Dump\n    #file_name = f\"{name}.sav\"\n    pickle.dump(model,open(f\"{name}.h5\",\"wb\"))\n    #pickle.dump(model,open(file_name,'wb'))\n    #with open(f'{file_name[:-4]}','wb') as files:\n        #pickle.dump(model,files)\n    print(name,\" - Saved\")\n    \n    R_sq_temp = cross_val_score(model, x, y, cv=cv, scoring='r2').mean()\n    R_sq.append(R_sq_temp)\n    print(\"R_sq - \", R_sq_temp)\n    ts2 = time.time()\n    print(\"Time taken (in mins) - \",(ts2-ts1)/60)\n    print(\"*-*\"*20)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:42:25.193211Z","iopub.execute_input":"2022-08-24T16:42:25.193787Z","iopub.status.idle":"2022-08-24T16:42:25.205988Z","shell.execute_reply.started":"2022-08-24T16:42:25.193745Z","shell.execute_reply":"2022-08-24T16:42:25.204558Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, \n                              AdaBoostRegressor)\n\nnames = ['Linear Regression', 'Ridge Regression', 'Lasso Regression',\n         'K Neighbors Regressor', 'Decision Tree Regressor', \n         'Random Forest Regressor', 'Gradient Boosting Regressor',\n         'Adaboost Regressor']\nmodels = [LinearRegression(), Ridge(), Lasso(),\n          KNeighborsRegressor(), DecisionTreeRegressor(),\n          RandomForestRegressor(), GradientBoostingRegressor(), \n          AdaBoostRegressor()]\n\n#Running all algorithms\nfor name, model in zip(names, models):\n    input_scores(name, model,X_train_nosplit, y_train_nosplit)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T16:42:25.207904Z","iopub.execute_input":"2022-08-24T16:42:25.208462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation = pd.DataFrame({'Model': Model,\n                           'RMSE': RMSE,\n                           'R Squared': R_sq})\nprint(\"FOLLOWING ARE THE TRAINING SCORES: \")\nevaluation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}