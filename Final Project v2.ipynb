{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c934cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "Pandas version -  1.4.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary libraries imported\n"
     ]
    }
   ],
   "source": [
    "print(\"Started\")\n",
    "import numpy as np, pandas as pd\n",
    "print(\"Pandas version - \", pd.__version__)\n",
    "from pandas import MultiIndex, Int16Dtype\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except:\n",
    "    !pip install seaborn\n",
    "    import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import cupy, cudf\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Importing RFE and LinearRegression\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "except:\n",
    "    !python -m pip install statsmodels\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model,tree,svm\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "except:\n",
    "    !pip install pickle5\n",
    "    import pickle\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"All necessary libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42435faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6036000, 8)  - Training dataset shape\n",
      "(4024000, 7)  - Testing dataset shape\n",
      "(4024000, 2)  - Sample Submission dataset shape\n"
     ]
    }
   ],
   "source": [
    "traindf = pd.read_csv('train.csv')\n",
    "testdf = pd.read_csv('test.csv')\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(traindf.shape, \" - Training dataset shape\")\n",
    "print(testdf.shape, \" - Testing dataset shape\")\n",
    "print(sample_sub.shape, \" - Sample Submission dataset shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433163d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.columns\n",
    "\n",
    "# Adding feature\n",
    "\n",
    "traindf['time_delta'] = traindf.groupby('breath_id')['time_step'].diff()\n",
    "#testdf['time_delta'] = testdf.groupby('breath_id')['time_step'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcf2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = ['breath_id','R','C','time_step','u_in','u_out']\n",
    "numerical_features = ['time_step','u_in']\n",
    "categorical_features = ['R','C','u_out','breath_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010bded7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#!Tensor Flow Addons\\n\\n!pip install -U tensorflow-addons\\n!pip install -q \"tqdm>=4.36.1\"\\nprint(\"Done 1\")\\n\\ntry:\\n    import tensorflow as tf\\nexcept:\\n    !pip install tensorflow\\n    import tensorflow as tf\\n\\nimport tensorflow_addons as tfa\\nprint(\"Done 2\")\\n\\nfrom tensorflow.keras.datasets import mnist\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\\nprint(\"Done 1\")\\n\\nimport tqdm\\n\\n# quietly deep-reload tqdm\\nimport sys\\nfrom IPython.lib import deepreload \\n\\nprint(\"Tensor flow addons added\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#!Tensor Flow Addons\n",
    "\n",
    "!pip install -U tensorflow-addons\n",
    "!pip install -q \"tqdm>=4.36.1\"\n",
    "print(\"Done 1\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except:\n",
    "    !pip install tensorflow\n",
    "    import tensorflow as tf\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "print(\"Done 2\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "print(\"Done 1\")\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# quietly deep-reload tqdm\n",
    "import sys\n",
    "from IPython.lib import deepreload \n",
    "\n",
    "print(\"Tensor flow addons added\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0f51bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstdout = sys.stdout\\nsys.stdout = open('junk','w')\\ndeepreload.reload(tqdm)\\nsys.stdout = stdout\\n\\n\\ntqdm.__version__\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "stdout = sys.stdout\n",
    "sys.stdout = open('junk','w')\n",
    "deepreload.reload(tqdm)\n",
    "sys.stdout = stdout\n",
    "\n",
    "\n",
    "tqdm.__version__\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c6c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186b5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding features in the dataframe\n",
    "\n",
    "def add_features(df):\n",
    "    #https://www.kaggle.com/code/papernist/google-brain\n",
    "    df = df.copy()\n",
    "    \n",
    "    df_group = df.groupby(['breath_id'])\n",
    "    \n",
    "    \n",
    "    feature_list = ['u_in', 'time_step', 'cross']\n",
    "    \n",
    "    df['cross']= df['u_in'] * df['u_out']\n",
    "    df['area_out']= df['time_step'] * df['u_out']\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    \n",
    "    # add\n",
    "    df['air_flow_rate'] = df['u_out'] - (df['u_in']/100.0)\n",
    "    df['air_flow_area'] = df['air_flow_rate'] * df['time_step']\n",
    "    print(\"Step-1...Completed\")\n",
    "    \n",
    "    # cumsum cummean\n",
    "    df['one'] = 1\n",
    "    df['count'] = df_group['one'].cumsum()\n",
    "    for feature in feature_list:\n",
    "        df[f'{feature}_cumsum'] = df_group[feature].cumsum()\n",
    "        df[f'{feature}_cummean'] = df[f'{feature}_cumsum'] / df['count']\n",
    "        \n",
    "    print(\"Step-2 cumsum cummean ...Completed\")\n",
    "    # lagging\n",
    "    use_lags = 4\n",
    "    for lag in range(1, use_lags+1):\n",
    "        for feature in feature_list:\n",
    "            # lag \n",
    "            df[f'{feature}_lag_{lag}'] = df_group[feature].shift(lag)\n",
    "            # inverse lag\n",
    "            df[f'{feature}_lag_inverse_{lag}'] = df_group[feature].shift(-lag)\n",
    "\n",
    "            # dif lag\n",
    "            df[f'{feature}_lag_diff_{lag}'] = df[feature] - df[f'{feature}_lag_{lag}']\n",
    "\n",
    "            # dif inverse lag\n",
    "            df[f'{feature}_lag_inverse_diff_{lag}'] = df[feature] - df[f'{feature}_lag_inverse_{lag}']\n",
    "\n",
    "            df = df.drop(columns=[f'{feature}_lag_{lag}', f'{feature}_lag_inverse_{lag}'])\n",
    "        \n",
    "    df = df.fillna(0)\n",
    "    print(\"Step-3 lagging ...Completed\")\n",
    "    \n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "    df = df.fillna(0)\n",
    "    print(\"Step-4 categorical ...Completed\")\n",
    "    \n",
    "    rolling_list = [15]\n",
    "    for roll in rolling_list:\n",
    "        for feature in feature_list:\n",
    "            df[[f'{roll}_{feature}_sum',f'{roll}_{feature}_min',\n",
    "                f'{roll}_{feature}_max',f'{roll}_{feature}_mean']] = (df_group[feature]\\\n",
    "                                                                  .rolling(window=roll,min_periods=1)\\\n",
    "                                                                  .agg({f'{roll}_{feature}_sum':'sum',\n",
    "                                                                        f'{roll}_{feature}_min':'min',\n",
    "                                                                        f'{roll}_{feature}_max':'max',\n",
    "                                                                        f'{roll}_{feature}_mean':'mean'})\\\n",
    "                                                                   .reset_index(level=0,drop=True))\n",
    "    \n",
    "    print(\"Step-5 Sliding window...Completed\")\n",
    "    print()\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    df = df.drop(['id', 'breath_id','one','count'], axis=1)\n",
    "    \n",
    "    return df.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bdba50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-1...Completed\n",
      "Step-2 cumsum cummean ...Completed\n",
      "Step-3 lagging ...Completed\n",
      "Step-4 categorical ...Completed\n",
      "Step-5 Sliding window...Completed\n",
      "\n",
      "**********************************************************************\n",
      "(6036000, 67)  - Feature added training dataset shape\n",
      "Wall time: 5min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = add_features(traindf)\n",
    "#test = add_features(testdf)\n",
    "\n",
    "print(\"*\"*70)\n",
    "print(train.shape, \" - Feature added training dataset shape\")\n",
    "#print(test.shape, \" - Features added testing dataset shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ccab2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Number of Binary Categorical Columns\n",
      "51 Number of Numerical Columns\n",
      "67 Sum of Binary & Numerical Columns\n"
     ]
    }
   ],
   "source": [
    "binary_col = []\n",
    "num_col = []\n",
    "\n",
    "for columnname in train.columns:\n",
    "  if len(set(train[columnname])) != 2:\n",
    "    num_col.append(columnname)\n",
    "  else:\n",
    "    binary_col.append(columnname)\n",
    "\n",
    "train_numcol = num_col.copy()\n",
    "train_numcol.remove('pressure')\n",
    "\n",
    "print(len(binary_col), \"Number of Binary Categorical Columns\")\n",
    "print(len(num_col),\"Number of Numerical Columns\")\n",
    "print(len(binary_col)+len(num_col), \"Sum of Binary & Numerical Columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5c7f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Done\n",
      "**********************************************************************\n",
      "Splitting the data into X train & Y train\n",
      "(4225200, 66) X train shape\n",
      "(4225200,) Y train shape\n",
      "**********************************************************************\n",
      "Splitting the data into X test & Y test\n",
      "(1810800, 66) X test shape\n",
      "(1810800,) Y test shape\n",
      "**********************************************************************\n",
      "No Split Data\n",
      "(6036000, 66) X train shape\n",
      "(6036000,) Y train shape\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(train, train_size = 0.7, test_size = 0.3, random_state = 100)\n",
    "print(\"Split Done\")\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, train_test_split\n",
    "\n",
    "trainsplitcopy = df_train.copy()\n",
    "testsplitcopy = df_test.copy()\n",
    "traincopy = train.copy()\n",
    "\n",
    "y_train = trainsplitcopy.pop('pressure')\n",
    "X_train = trainsplitcopy\n",
    "\n",
    "y_test = testsplitcopy.pop('pressure')\n",
    "X_test = testsplitcopy\n",
    "\n",
    "y_train_nosplit = traincopy.pop('pressure')\n",
    "X_train_nosplit = traincopy\n",
    "\n",
    "\n",
    "\n",
    "print(\"*\"*70)\n",
    "print(\"Splitting the data into X train & Y train\")\n",
    "print(X_train.shape, \"X train shape\")\n",
    "print(y_train.shape, \"Y train shape\")\n",
    "\n",
    "print(\"*\"*70)\n",
    "print(\"Splitting the data into X test & Y test\")\n",
    "print(X_test.shape, \"X test shape\")\n",
    "print(y_test.shape, \"Y test shape\")\n",
    "\n",
    "print(\"*\"*70)\n",
    "print(\"No Split Data\")\n",
    "print(X_train_nosplit.shape, \"X train shape\")\n",
    "print(y_train_nosplit.shape, \"Y train shape\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e208ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00e6efad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>cross</th>\n",
       "      <th>area_out</th>\n",
       "      <th>area</th>\n",
       "      <th>air_flow_rate</th>\n",
       "      <th>air_flow_area</th>\n",
       "      <th>u_in_cumsum</th>\n",
       "      <th>u_in_cummean</th>\n",
       "      <th>...</th>\n",
       "      <th>15_u_in_max</th>\n",
       "      <th>15_u_in_mean</th>\n",
       "      <th>15_time_step_sum</th>\n",
       "      <th>15_time_step_min</th>\n",
       "      <th>15_time_step_max</th>\n",
       "      <th>15_time_step_mean</th>\n",
       "      <th>15_cross_sum</th>\n",
       "      <th>15_cross_min</th>\n",
       "      <th>15_cross_max</th>\n",
       "      <th>15_cross_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499512</td>\n",
       "      <td>0.254395</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011459</td>\n",
       "      <td>0.183960</td>\n",
       "      <td>0.134155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.408203</td>\n",
       "      <td>0.252686</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183960</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011459</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022980</td>\n",
       "      <td>0.225220</td>\n",
       "      <td>0.135010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014145</td>\n",
       "      <td>0.387451</td>\n",
       "      <td>0.250244</td>\n",
       "      <td>0.015045</td>\n",
       "      <td>0.136597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225220</td>\n",
       "      <td>0.136597</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022980</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034576</td>\n",
       "      <td>0.228149</td>\n",
       "      <td>0.135620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>0.385986</td>\n",
       "      <td>0.248169</td>\n",
       "      <td>0.023422</td>\n",
       "      <td>0.159546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228149</td>\n",
       "      <td>0.159546</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034576</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046204</td>\n",
       "      <td>0.253662</td>\n",
       "      <td>0.136353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032043</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.245239</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.178345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253662</td>\n",
       "      <td>0.178345</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046204</td>\n",
       "      <td>0.025223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step      u_in  time_delta  cross  area_out      area  air_flow_rate  \\\n",
       "0   0.000000  0.000834    0.000000    0.0       0.0  0.000000       0.499512   \n",
       "1   0.011459  0.183960    0.134155    0.0       0.0  0.005760       0.408203   \n",
       "2   0.022980  0.225220    0.135010    0.0       0.0  0.014145       0.387451   \n",
       "3   0.034576  0.228149    0.135620    0.0       0.0  0.021561       0.385986   \n",
       "4   0.046204  0.253662    0.136353    0.0       0.0  0.032043       0.373047   \n",
       "\n",
       "   air_flow_area  u_in_cumsum  u_in_cummean  ...  15_u_in_max  15_u_in_mean  \\\n",
       "0       0.254395     0.000031      0.000834  ...     0.000834      0.000834   \n",
       "1       0.252686     0.006783      0.092346  ...     0.183960      0.092346   \n",
       "2       0.250244     0.015045      0.136597  ...     0.225220      0.136597   \n",
       "3       0.248169     0.023422      0.159546  ...     0.228149      0.159546   \n",
       "4       0.245239     0.032715      0.178345  ...     0.253662      0.178345   \n",
       "\n",
       "   15_time_step_sum  15_time_step_min  15_time_step_max  15_time_step_mean  \\\n",
       "0          0.000000               0.0          0.000000           0.000000   \n",
       "1          0.000836               0.0          0.011459           0.006271   \n",
       "2          0.002514               0.0          0.022980           0.012566   \n",
       "3          0.005035               0.0          0.034576           0.018890   \n",
       "4          0.008408               0.0          0.046204           0.025223   \n",
       "\n",
       "   15_cross_sum  15_cross_min  15_cross_max  15_cross_mean  \n",
       "0           0.0           0.0           0.0            0.0  \n",
       "1           0.0           0.0           0.0            0.0  \n",
       "2           0.0           0.0           0.0            0.0  \n",
       "3           0.0           0.0           0.0            0.0  \n",
       "4           0.0           0.0           0.0            0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the features\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train_nosplit[train_numcol])\n",
    "train_scaled_nosplit = pd.DataFrame(scaler.transform(X_train_nosplit[train_numcol]),\n",
    "                              columns = X_train_nosplit[train_numcol].columns)\n",
    "train_scaled_nosplit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d050f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c06e3e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_step', 'u_in', 'time_delta', 'cross', 'area_out', 'area',\n",
       "       'air_flow_rate', 'air_flow_area', 'u_in_cumsum', 'u_in_cummean',\n",
       "       'time_step_cumsum', 'time_step_cummean', 'cross_cumsum',\n",
       "       'cross_cummean', 'u_in_lag_diff_1', 'u_in_lag_inverse_diff_1',\n",
       "       'time_step_lag_diff_1', 'time_step_lag_inverse_diff_1',\n",
       "       'cross_lag_diff_1', 'cross_lag_inverse_diff_1', 'u_in_lag_diff_2',\n",
       "       'u_in_lag_inverse_diff_2', 'time_step_lag_diff_2',\n",
       "       'time_step_lag_inverse_diff_2', 'cross_lag_diff_2',\n",
       "       'cross_lag_inverse_diff_2', 'u_in_lag_diff_3',\n",
       "       'u_in_lag_inverse_diff_3', 'time_step_lag_diff_3',\n",
       "       'time_step_lag_inverse_diff_3', 'cross_lag_diff_3',\n",
       "       'cross_lag_inverse_diff_3', 'u_in_lag_diff_4',\n",
       "       'u_in_lag_inverse_diff_4', 'time_step_lag_diff_4',\n",
       "       'time_step_lag_inverse_diff_4', 'cross_lag_diff_4',\n",
       "       'cross_lag_inverse_diff_4', '15_u_in_sum', '15_u_in_min', '15_u_in_max',\n",
       "       '15_u_in_mean', '15_time_step_sum', '15_time_step_min',\n",
       "       '15_time_step_max', '15_time_step_mean', '15_cross_sum', '15_cross_min',\n",
       "       '15_cross_max', '15_cross_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled_nosplit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efd21b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text123456'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"text123456.sav\"\n",
    "text[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53aa72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will save the model performance metrics in a DataFrame\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "Model = []\n",
    "RMSE = []\n",
    "R_sq = []\n",
    "cv = KFold(5, random_state = 1,shuffle=True)\n",
    "\n",
    "#Creating a Function to append the cross validation scores of the algorithms\n",
    "def input_scores(name, model, x, y):\n",
    "    Model.append(name)\n",
    "    print(name,\" - Started\")\n",
    "    rmse_tmp = np.sqrt((-1) * cross_val_score(model, x, y, cv=cv, scoring='neg_mean_squared_error').mean())\n",
    "    RMSE.append(rmse_tmp)\n",
    "    print(name, \" - RSME - \", rmse_tmp)\n",
    "    #Pickle Dump\n",
    "    #file_name = f\"{name}.sav\"\n",
    "    pickle.dump(model,open(f\"{name}.h5\",\"wb\"))\n",
    "    #pickle.dump(model,open(file_name,'wb'))\n",
    "    #with open(f'{file_name[:-4]}','wb') as files:\n",
    "        #pickle.dump(model,files)\n",
    "    print(name,\" - Saved\")\n",
    "    \n",
    "    R_sq_temp = cross_val_score(model, x, y, cv=cv, scoring='r2').mean()\n",
    "    R_sq.append(R_sq_temp)\n",
    "    print(\"R_sq - \", R_sq_temp)\n",
    "    print(\"*-*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b79fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression  - Started\n",
      "Linear Regression  - RSME -  rmse_tmp\n",
      "Linear Regression  - Saved\n",
      "R_sq -  0.7368980399949455\n",
      "*-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-*\n",
      "Ridge Regression  - Started\n",
      "Ridge Regression  - RSME -  rmse_tmp\n",
      "Ridge Regression  - Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 762, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 572, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 130, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=['csr', 'csc'],\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 683, in check_array\n",
      "    array = np.array(array, dtype=dtype, order=order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.37 GiB for an array with shape (4828800, 66) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 762, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 572, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 130, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=['csr', 'csc'],\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 683, in check_array\n",
      "    array = np.array(array, dtype=dtype, order=order)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.37 GiB for an array with shape (4828800, 66) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_sq -  nan\n",
      "*-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-*\n",
      "Lasso Regression  - Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 844, in fit\n",
      "    self.path(X, y[:, k],\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 530, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"sklearn\\linear_model\\_cd_fast.pyx\", line 124, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.37 GiB for an array with shape (4828800, 66) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 844, in fit\n",
      "    self.path(X, y[:, k],\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 530, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"sklearn\\linear_model\\_cd_fast.pyx\", line 124, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.37 GiB for an array with shape (4828800, 66) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression  - RSME -  rmse_tmp\n",
      "Lasso Regression  - Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 844, in fit\n",
      "    self.path(X, y[:, k],\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 530, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"sklearn\\linear_model\\_cd_fast.pyx\", line 124, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.37 GiB for an array with shape (4828800, 66) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 844, in fit\n",
      "    self.path(X, y[:, k],\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 530, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"sklearn\\linear_model\\_cd_fast.pyx\", line 124, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.37 GiB for an array with shape (4828800, 66) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 844, in fit\n",
      "    self.path(X, y[:, k],\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 530, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"sklearn\\linear_model\\_cd_fast.pyx\", line 124, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.37 GiB for an array with shape (4828800, 66) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 844, in fit\n",
      "    self.path(X, y[:, k],\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 530, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "  File \"sklearn\\linear_model\\_cd_fast.pyx\", line 124, in sklearn.linear_model._cd_fast.enet_coordinate_descent\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.37 GiB for an array with shape (4828800, 66) and data type float64\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_sq -  nan\n",
      "*-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-*\n",
      "K Neighbors Regressor  - Started\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor, \n",
    "                              AdaBoostRegressor)\n",
    "\n",
    "names = ['Linear Regression', 'Ridge Regression', 'Lasso Regression',\n",
    "         'K Neighbors Regressor', 'Decision Tree Regressor', \n",
    "         'Random Forest Regressor', 'Gradient Boosting Regressor',\n",
    "         'Adaboost Regressor']\n",
    "models = [LinearRegression(), Ridge(), Lasso(),\n",
    "          KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(), GradientBoostingRegressor(), \n",
    "          AdaBoostRegressor()]\n",
    "\n",
    "#Running all algorithms\n",
    "for name, model in zip(names, models):\n",
    "    input_scores(name, model,X_train_nosplit, y_train_nosplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f159d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'Model': Model,\n",
    "                           'RMSE': RMSE,\n",
    "                           'R Squared': R_sq})\n",
    "print(\"FOLLOWING ARE THE TRAINING SCORES: \")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300eaf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213e948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642ddaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1c7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "58dbfdb34cf82127b32c5737e6183911655ff227e5c11e8f5e4b25048ae98ef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
